{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nOuO8wFMW3wu"
   },
   "outputs": [],
   "source": [
    "# !pip install rdkit\n",
    "# !pip install torch\n",
    "# !pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cK2D6dVRPkLG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle as pi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2Sxq8SOUQ-P9"
   },
   "outputs": [],
   "source": [
    "clf = pi.load(open('weights/clf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rG0k5YEGSuQz"
   },
   "outputs": [],
   "source": [
    "drug = 'CN1C=NC2=C1C(=O)N(C)C(=O)N2C'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "generated_example = 'NC(=O)CN1CCCC1=O'"
   ],
   "metadata": {
    "id": "unPeDIOzOgfN"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_descriptors(smiles):\n",
    "  \n",
    "  descriptor_names = list(rdMolDescriptors.Properties.GetAvailableProperties())\n",
    "  get_descriptors = rdMolDescriptors.Properties(descriptor_names)\n",
    "  \n",
    "  molecule_object = Chem.MolFromSmiles(smiles)\n",
    "  final_descriptors = np.array(get_descriptors.ComputeProperties(molecule_object)).reshape((-1, 43))\n",
    "\n",
    "  return final_descriptors\n",
    "\n",
    "\n",
    "def get_clf_input(coformer_smiles, drug_smiles=drug):\n",
    "\n",
    "  drug_descriptors, coformer_descriptors = generate_descriptors(drug_smiles), generate_descriptors(coformer_smiles)\n",
    "\n",
    "  final_input = np.concatenate((drug_descriptors, coformer_descriptors), axis=1)\n",
    "\n",
    "  return final_input\n",
    "\n",
    "\n",
    "def calculate_clf_error(coformer_smiles, desired_clf_output=1, drug_smiles=drug, classifier=clf):\n",
    "\n",
    "  clf_input = get_clf_input(coformer_smiles, drug_smiles)\n",
    "  clf_prediction = classifier.predict_proba(clf_input)[:,desired_clf_output]\n",
    "\n",
    "  error = tf.keras.metrics.binary_crossentropy(desired_clf_output, \n",
    "                                               clf_prediction)\n",
    "\n",
    "  return float(error)"
   ],
   "metadata": {
    "id": "Z_iVd-pxa3X3"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vg6G_gG5ck1X"
   },
   "source": [
    "### Объединенная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jGEs9chj-2Hv"
   },
   "outputs": [],
   "source": [
    "from model import MolGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "o4hwBvIShYlz"
   },
   "outputs": [],
   "source": [
    "#создание списка SMILES\n",
    "with open('data/database_cof_100smb_kekule.csv', \"r\") as file:\n",
    "  data = [molecule.replace('\\n', '') for molecule in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#загрузка предобученной только на ChemBL генеративной модели и ее дообучение\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# gan_mol = pi.load(open('weights/gan_mol7_50ksteps_100symb_kekuke.pkl', 'rb'))\u001B[39;00m\n\u001B[0;32m      3\u001B[0m gan_mol \u001B[38;5;241m=\u001B[39m MolGen(data\u001B[38;5;241m=\u001B[39mdata, clf_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweights/clf.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m gan_mol\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mpi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweights/gan_mol7_50ksteps_100symb_kekuke.pkl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# gan_mol.load('weights/gan_mol7_50ksteps_100symb_kekuke.pkl')\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# загрузчик данных для модели\u001B[39;00m\n\u001B[0;32m     10\u001B[0m loader \u001B[38;5;241m=\u001B[39m gan_mol\u001B[38;5;241m.\u001B[39mcreate_dataloader(data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\storage.py:222\u001B[0m, in \u001B[0;36m_load_from_bytes\u001B[1;34m(b)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_from_bytes\u001B[39m(b):\n\u001B[1;32m--> 222\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBytesIO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\serialization.py:713\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    711\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mload(opened_file)\n\u001B[0;32m    712\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m--> 713\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_legacy_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\serialization.py:930\u001B[0m, in \u001B[0;36m_legacy_load\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    928\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m    929\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m--> 930\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m deserialized_storage_keys \u001B[38;5;241m=\u001B[39m pickle_module\u001B[38;5;241m.\u001B[39mload(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m    934\u001B[0m offset \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mtell() \u001B[38;5;28;01mif\u001B[39;00m f_should_read_directly \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\serialization.py:876\u001B[0m, in \u001B[0;36m_legacy_load.<locals>.persistent_load\u001B[1;34m(saved_id)\u001B[0m\n\u001B[0;32m    872\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_torch_load_uninitialized \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[0;32m    874\u001B[0m     \u001B[38;5;66;03m# stop wrapping with _TypedStorage\u001B[39;00m\n\u001B[0;32m    875\u001B[0m     deserialized_objects[root_key] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39m_TypedStorage(\n\u001B[1;32m--> 876\u001B[0m         wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    877\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    879\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m deserialized_objects[root_key]\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m view_metadata \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\serialization.py:175\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[1;34m(storage, location)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[0;32m    174\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[1;32m--> 175\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    176\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    177\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\serialization.py:152\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[1;34m(obj, location)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 152\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_cuda_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    154\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice(device):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\serialization.py:136\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[1;34m(location)\u001B[0m\n\u001B[0;32m    133\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_get_device_index(location, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m--> 136\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    137\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    138\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    139\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    140\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    141\u001B[0m device_count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "#загрузка предобученной только на ChemBL генеративной модели и ее дообучение\n",
    "# gan_mol = pi.load(open('weights/gan_mol7_50ksteps_100symb_kekuke.pkl', 'rb'))\n",
    "gan_mol = MolGen(data=data, clf_path='weights/clf.pkl')\n",
    "gan_mol.load_state_dict(pi.load(\n",
    "  open('weights/gan_mol7_50ksteps_100symb_kekuke.pkl', 'rb')))\n",
    "\n",
    "# gan_mol.load('weights/gan_mol7_50ksteps_100symb_kekuke.pkl')\n",
    "\n",
    "# загрузчик данных для модели\n",
    "loader = gan_mol.create_dataloader(data, batch_size=20, shuffle=True, num_workers=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwklxOX8hwOj"
   },
   "outputs": [],
   "source": [
    "# train model for 10000 steps\n",
    "gan_mol.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLyRWJjUxN5a"
   },
   "outputs": [],
   "source": [
    "import warnings #возникает одна и та же ошибка\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "training_steps = 1000\n",
    "cofomers_training_history = gan_mol.train_n_steps(loader, max_step=training_steps, evaluate_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W74j03r8SWj_"
   },
   "source": [
    "### График измененеие clf loss в процессе обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noi90P1GTUsx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x1 = np.arange(training_steps)\n",
    "x2 = np.arange(training_steps)\n",
    "\n",
    "# clf_loss_chembl = chembl_training_history['classifier_loss']\n",
    "clf_loss_cofomers = cofomers_training_history['classifier_loss']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# пока чтобы просто работало, потому что метрики первого обучения не вытащить, судя по всему\n",
    "clf_loss_chembl = np.sqrt(\n",
    "  np.array(\n",
    "  [0.6666666666666666, 0.618421052631579, 0.5135135135135135, 0.4050632911392405, 0.3, 0.34285714285714286, 0.2875, 0.23333333333333334, 0.4574468085106383, 0.5157894736842106, 0.7065217391304348, 0.5952380952380952, 0.5909090909090909, 0.5, 0.4878048780487805, 0.36764705882352944, 0.2830188679245283, 0.375, 0.44, 0.3220338983050847, 0.475, 0.7755102040816326, 0.7727272727272727, 0.66, 0.6428571428571429, 0.48214285714285715, 0.48333333333333334, 0.5625, 0.4069767441860465, 0.4090909090909091, 0.38372093023255816, 0.4880952380952381, 0.5116279069767442, 0.49333333333333335, 0.5945945945945946, 0.3977272727272727, 0.32222222222222224, 0.3333333333333333, 0.3522727272727273, 0.36046511627906974, 0.4431818181818182, 0.38095238095238093, 0.47674418604651164, 0.5851063829787234, 0.6222222222222222, 0.627906976744186, 0.7228915662650602, 0.6046511627906976, 0.6951219512195121, 0.7333333333333333, 0.6477272727272727, 0.7439024390243902, 0.5444444444444444, 0.7093023255813954, 0.5, 0.5, 0.44047619047619047, 0.5227272727272727, 0.40789473684210525, 0.34146341463414637, 0.45555555555555555, 0.4090909090909091, 0.4714285714285714, 0.48717948717948717, 0.5972222222222222, 0.4594594594594595, 0.5294117647058824, 0.5735294117647058, 0.5384615384615384, 0.47560975609756095, 0.4367816091954023, 0.5217391304347826, 0.4186046511627907, 0.36585365853658536, 0.4230769230769231, 0.46153846153846156, 0.47619047619047616, 0.4868421052631579, 0.5606060606060606, 0.5714285714285714, 0.4166666666666667, 0.5217391304347826, 0.38823529411764707, 0.3333333333333333, 0.4186046511627907, 0.43617021276595747, 0.36666666666666664, 0.40476190476190477, 0.45555555555555555, 0.5977011494252874, 0.46987951807228917, 0.4148936170212766, 0.4418604651162791, 0.36666666666666664, 0.3953488372093023, 0.38372093023255816, 0.5760869565217391, 0.47, 0.5416666666666666, 0.4791666666666667]\n",
    ")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EoNPydhaTjlL"
   },
   "outputs": [],
   "source": [
    "# построение графика\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(x1, clf_loss_cofomers, label = \"Предобученная на коформерах модель\")\n",
    "plt.plot(x2, clf_loss_chembl, label = \"Предобученной только на ChemBL модель\")\n",
    "plt.title('Изменение clf loss в процессе обучения')\n",
    "plt.xlabel('Итерация обучения')\n",
    "plt.ylabel('clf loss mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# discriminator + generator loss plot\n",
    "x = np.arange(training_steps)\n",
    "discr_loss = cofomers_training_history['discriminator_loss']\n",
    "gen_loss = cofomers_training_history['generator_loss']\n",
    "plt.plot(x, discr_loss, label='Discriminator loss')\n",
    "plt.plot(x, gen_loss, label='Generator loss')\n",
    "plt.title('GAN metrics during training')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Mean loss')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# discriminator + generator + classifier loss plot\n",
    "x = np.arange(training_steps)\n",
    "discr_loss = cofomers_training_history['discriminator_loss']\n",
    "gen_loss = cofomers_training_history['generator_loss']\n",
    "classifier_loss = cofomers_training_history['classifier_loss']\n",
    "plt.plot(x, discr_loss, label='Discriminator loss')\n",
    "plt.plot(x, gen_loss, label='Generator loss')\n",
    "plt.plot(x, classifier_loss, label='Classifier loss')\n",
    "plt.title('GAN and classifier metrics during training')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Mean loss')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "w6bnkngncdHR"
   ],
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
