{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4POmPZknGW5Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import pickle as pi\n",
        "from rdkit import Chem\n",
        "from model import MolGen\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZS6j4GLRGW5d"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "# data = []\n",
        "# with open('qm9.csv', \"r\") as f:\n",
        "#     for line in f.readlines()[1:]:\n",
        "#         data.append(line.split(\",\")[1])\n",
        "\n",
        "# data = pd.read_csv(\"database_final_all_100smb_kekule.csv\")\n",
        "zf = zipfile.ZipFile(\"database/concatenated_smiles.zip\", \"r\")\n",
        "data = pd.read_csv(zf.open(\"concatenated_smiles.csv\"))\n",
        "x = data[\"smiles\"]\n",
        "\n",
        "clf = pi.load(open(\"weights/clf.pkl\", \"rb\"))\n",
        "\n",
        "# create model\n",
        "gan_mol = MolGen(x, classifier=clf, hidden_dim=128, lr=5e-4, device=\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgvHRL4GW5g"
      },
      "source": [
        "### Pre-train GAN on CHEMBL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCHXixYVGW5k"
      },
      "outputs": [],
      "source": [
        "# create dataloader\n",
        "loader = gan_mol.create_dataloader(x, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# initial training for discriminator\n",
        "initial_history = gan_mol.initial_train_n_steps(loader, max_step=2000, evaluate_every=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgPX3kynGW5p"
      },
      "outputs": [],
      "source": [
        "# stop GAN training\n",
        "gan_mol.eval()\n",
        "print('ok')\n",
        "\n",
        "# save the model weights\n",
        "torch.save(gan_mol.state_dict(), \"weights/initial_discr_mol_gan_new.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfTDcwtgfFeG"
      },
      "source": [
        "### Plot GAN Discriminator inital training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldbdCo0HfEmh"
      },
      "outputs": [],
      "source": [
        "steps = np.arange(len(initial_history[\"loss_disc\"]))\n",
        "plt.plot(steps, initial_history[\"loss_disc\"], label=\"Initial discriminator loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "grOcbZ4weoMT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['SF']\n",
            "valid: 0.01 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['I']\n",
            "valid: 0.01 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['I', 'SP']\n",
            "valid: 0.02 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['F']\n",
            "valid: 0.01 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['FI', 'O']\n",
            "valid: 0.02 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['P']\n",
            "valid: 0.01 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n",
            "['B']\n",
            "valid: 0.01 \n",
            " \n",
            "\n",
            "[]\n",
            "valid: 0.0 \n",
            " \n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [5], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# train model for 10000 steps\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# set GAN to the training mode\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[39m# create dataloader\u001b[39;00m\n\u001b[0;32m     11\u001b[0m loader \u001b[39m=\u001b[39m gan_mol\u001b[39m.\u001b[39mcreate_dataloader(x, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m pretrain_history \u001b[39m=\u001b[39m gan_mol\u001b[39m.\u001b[39;49mtrain_n_steps(loader, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpretrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, max_step\u001b[39m=\u001b[39;49m\u001b[39m5000\u001b[39;49m, evaluate_every\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
            "File \u001b[1;32md:\\stuff\\code\\aiLab\\molgen\\model.py:322\u001b[0m, in \u001b[0;36mMolGen.train_n_steps\u001b[1;34m(self, train_loader, mode, max_step, evaluate_every)\u001b[0m\n\u001b[0;32m    319\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iter_loader)\n\u001b[0;32m    321\u001b[0m \u001b[39m# model update\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m local_history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(batch)\n\u001b[0;32m    324\u001b[0m \u001b[39m# model save best\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39m# if step > 0:\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m#     discr_loss_condition = statistics.mean(history[\"loss_disc\"]) > statistics.mean(local_history[\"loss_disc\"])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39m#     if discr_loss_condition or gen_loss_condition: \u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m#         torch.save(self.state_dict(), f\"{mode}_best_model.pt\")\u001b[39;00m\n\u001b[0;32m    333\u001b[0m history[\u001b[39m\"\u001b[39m\u001b[39mloss_disc\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(local_history[\u001b[39m\"\u001b[39m\u001b[39mloss_disc\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "File \u001b[1;32md:\\stuff\\code\\aiLab\\molgen\\model.py:223\u001b[0m, in \u001b[0;36mMolGen.train_step\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39m# combined loss\u001b[39;00m\n\u001b[0;32m    222\u001b[0m discr_loss \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (real_loss \u001b[39m+\u001b[39m fake_loss)\n\u001b[1;32m--> 223\u001b[0m discr_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    225\u001b[0m \u001b[39m# clip grad\u001b[39;00m\n\u001b[0;32m    226\u001b[0m clip_grad_value_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39mparameters(), \u001b[39m0.1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\nshir\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[1;32mc:\\Users\\nshir\\miniconda3\\envs\\cheml\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train model for 10000 steps\n",
        "\n",
        "# set GAN to the training mode\n",
        "# gan_mol.train()\n",
        "\n",
        "# load initially trained discriminator weights\n",
        "# gan_mol = MolGen(x, clf, hidden_dim=64, lr=1e-4, device=\"cuda\")\n",
        "# gan_mol.load_state_dict(torch.load(\"initial_discr_mol_gan.pt\"))\n",
        "\n",
        "# create dataloader\n",
        "loader = gan_mol.create_dataloader(x, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "pretrain_history = gan_mol.train_n_steps(loader, mode=\"pretrain\", max_step=5000, evaluate_every=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "118Bj6FEe0um"
      },
      "outputs": [],
      "source": [
        "# stop GAN training\n",
        "gan_mol.eval()\n",
        "print('ok')\n",
        "\n",
        "# stop model training and save the model weights\n",
        "torch.save(gan_mol.state_dict(), \"weights/pretrain_mol_gan.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBeAOfH2GW5s"
      },
      "source": [
        "### Generate Smiles molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHo6xI1lTj-b"
      },
      "outputs": [],
      "source": [
        "from rdkit.Chem import PandasTools\n",
        "from tensorboard.notebook import display\n",
        "from rdkit.Chem import Draw\n",
        "# After training\n",
        "smiles_list = gan_mol.generate_n(100)\n",
        "\n",
        "valid_smiles = []\n",
        "for mol in smiles_list:\n",
        "  if Chem.MolFromSmiles(mol) is not None:\n",
        "    valid_smiles.append(Chem.MolFromSmiles(mol))\n",
        "# df = pd.DataFrame(valid_smiles, columns=[\"smiles\"])\n",
        "valid_smiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9NrJSaUU0EW"
      },
      "outputs": [],
      "source": [
        "Draw.MolsToGridImage(valid_smiles, molsPerRow=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srZo-8htGW5y"
      },
      "source": [
        "### Plot GAN pre-training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxYMR5LzVNaO"
      },
      "outputs": [],
      "source": [
        "pretrain_history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdC5HiF6GW50"
      },
      "outputs": [],
      "source": [
        "steps = np.arange(len(pretrain_history[\"loss_disc\"][:1000]))\n",
        "plt.plot(steps, pretrain_history[\"loss_disc\"][:1000], label=\"discriminator loss\")\n",
        "plt.plot(steps, pretrain_history[\"loss_gen\"][:1000], label=\"generator loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlfIpRCzGW51"
      },
      "source": [
        "### Train GAN on coformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSd84EeZGW52"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "coformer_data = pd.read_csv(\"database/database_cof_100smb_kekule.csv\")\n",
        "coformer_x = coformer_data[\"smiles\"]\n",
        "\n",
        "clf = pi.load(open(\"clf.pkl\", \"rb\"))\n",
        "\n",
        "gan_mol = MolGen(coformer_x, classifier=clf, hidden_dim=64, lr=1e-3, device=\"cpu\")\n",
        "gan_mol.load_state_dict(torch.load(\"weights/pretrained_mol_gan.pt\"))\n",
        "\n",
        "# set GAN to the training mode\n",
        "gan_mol.train()\n",
        "\n",
        "coformer_loader = gan_mol.create_dataloader(coformer_x, batch_size=128, shuffle=True, num_workers=4)\n",
        "\n",
        "coformer_history = gan_mol.train_n_steps_coformer(coformer_loader, max_step=5000, evaluate_every=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfOU0resGW53"
      },
      "outputs": [],
      "source": [
        "# save coformer trained GAN\n",
        "torch.save(gan_mol.state_dict(), \"weights/coformer_trained_gan_mol.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be5m3D5_GW54"
      },
      "source": [
        "### Generate Smiles molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmUoFRt3GW54"
      },
      "outputs": [],
      "source": [
        "# After training\n",
        "smiles_list = gan_mol.generate_n(8)\n",
        "\n",
        "# convert with rdkit\n",
        "mol_list = [Chem.MolFromSmiles(m) for m in smiles_list]\n",
        "\n",
        "# draw\n",
        "Chem.Draw.MolsToGridImage(mol_list, molsPerRow=4, subImgSize=(250, 250), maxMols=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdpsXhc0GW55"
      },
      "source": [
        "### Plot GAN coformer training loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnbFMpI8GW55"
      },
      "outputs": [],
      "source": [
        "steps = len(coformer_history[\"loss_discr\"])\n",
        "plt.plot(steps, coformer_history[\"loss_discr\"], label=\"discriminator loss\")\n",
        "plt.plot(steps, coformer_history[\"loss_gen\"], label=\"generator loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "cheml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a823354c1b58a1fc958a4ddcbba8e1ce2f53be2bee94ae58ffd9530ee8c23d3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
